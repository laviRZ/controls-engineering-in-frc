\section{Linear system discretization}
\label{sec:linear_system_zoh}
\index{discretization!linear system zero-order hold}

We're going to discretize the following continuous time state-space model
\begin{align*}
  \dot{\mat{x}} &= \mat{A}_c\mat{x} + \mat{B}_c\mat{u} + \mat{w} \\
  \mat{y} &= \mat{C}_c\mat{x} + \mat{D}_c\mat{u} + \mat{v}
\end{align*}

where $\mat{w}$ is the process noise, $\mat{v}$ is the measurement noise, and
both are zero-mean white noise sources with covariances of $\mat{Q}_c$ and
$\mat{R}_c$ respectively. $\mat{w}$ and $\mat{v}$ are defined as normally
distributed random variables.
\begin{align*}
  \mat{w} &\sim N(0, \mat{Q}_c) \\
  \mat{v} &\sim N(0, \mat{R}_c)
\end{align*}

Discretization is done using a zero-order hold. That is, the input is only
updated at discrete intervals and itâ€™s held constant between samples.

\subsection{Taylor series}
\index{discretization!Taylor series}
\begin{remark}
  Watch the ``Taylor series" video from 3Blue1Brown's \textit{Essence of
  calculus} series for an explanation of how the Taylor series expansion works.
  \begin{bookfigure}
    \qrcode{https://www.3blue1brown.com/lessons/taylor-series} \\
    ``Taylor series" (22 minutes) \\
    \footnotesize 3Blue1Brown \\
    \url{https://www.3blue1brown.com/lessons/taylor-series}
  \end{bookfigure}
\end{remark}

The definition for the matrix exponential and the approximations below all use
the \textit{Taylor series expansion}. The Taylor series is a method of
approximating a function like $e^t$ via the summation of weighted polynomial
terms like $t^k$. $e^t$ has the following Taylor series around $t = 0$.
\begin{equation*}
  e^t = \sum_{n = 0}^\infty \frac{t^n}{n!}
\end{equation*}

where a finite upper bound on the number of terms produces an approximation of
$e^t$. As $n$ increases, the polynomial terms increase in power and the weights
by which they are multiplied decrease. For $e^t$ and some other functions, the
Taylor series expansion equals the original function for all values of $t$ as
the number of terms approaches infinity.\footnote{Functions for which their
Taylor series expansion converges to and also equals it are called analytic
functions.} Figure \ref{fig:taylor_series} shows the Taylor series expansion of
$e^t$ around $t = 0$ for a varying number of terms.
\begin{svg}{build/\chapterpath/taylor_series}
  \caption{Taylor series expansions of $e^t$ around $t = 0$ for $n$ terms}
  \label{fig:taylor_series}
\end{svg}

We'll expand the first few terms of the Taylor series expansion in equation
\eqref{eq:mat_exp} for $\mat{X} = \mat{A}T$ so we can compare it with other
methods.
\begin{equation*}
  \sum_{k=0}^3 \frac{1}{k!} (\mat{A}T)^k = \mat{I} + \mat{A}T +
    \frac{1}{2}\mat{A}^2T^2 + \frac{1}{6}\mat{A}^3T^3
\end{equation*}

Table \ref{tab:disc_matrix} compares \gls{discretization} methods for the matrix
case, and table \ref{tab:disc_approx_matrix} compares their Taylor series
expansions. These use a more complex formula which we won't present here.
\begin{booktable}
  \begin{tabular}{|cl|}
    \hline
    \rowcolor{headingbg}
    \multicolumn{1}{|c}{\textbf{Method}} &
      \multicolumn{1}{c|}{\textbf{Conversion to $\mat{A}_d$}} \\
    \hline
    Zero-order hold & $e^{\mat{A}_c T}$ \\
    Bilinear &
      $\left(\mat{I} + \frac{1}{2}\mat{A}_c T\right)
        \left(\mat{I} - \frac{1}{2}\mat{A}_c T\right)^{-1}$ \\
    Backward Euler & $\left(\mat{I} - \mat{A}_c T\right)^{-1}$ \\
    Forward Euler & $\mat{I} + \mat{A}_c T$ \\
    \hline
  \end{tabular}
  \caption{Discretization methods (matrix case). The zero-order hold
    discretization method is exact.}
  \label{tab:disc_matrix}
\end{booktable}
\begin{booktable}
  \begin{tabular}{|cl|}
    \hline
    \rowcolor{headingbg}
    \multicolumn{1}{|c}{\textbf{Method}} &
      \multicolumn{1}{c|}{\textbf{Taylor series expansion}} \\
    \hline
    Zero-order hold &
      $\mat{I} + \mat{A}_c T + \frac{1}{2}\mat{A}_c^2T^2 +
        \frac{1}{6}\mat{A}_c^3T^3 + \ldots$ \\
    Bilinear &
      $\mat{I} + \mat{A}_c T + \frac{1}{2}\mat{A}_c^2T^2 +
        \frac{1}{4}\mat{A}_c^3T^3 + \ldots$ \\
    Backward Euler &
      $\mat{I} + \mat{A}_c T + \mat{A}_c^2T^2 + \mat{A}_c^3T^3 + \ldots$ \\
    Forward Euler & $\mat{I} + \mat{A}_c T$ \\
    \hline
  \end{tabular}
  \caption{Taylor series expansions of discretization methods (matrix case).
    The zero-order hold discretization method is exact.}
  \label{tab:disc_approx_matrix}
\end{booktable}

Each of them has different stability properties. The bilinear transform
preserves the (in)stability of the continuous time \gls{system}.

\subsection{Matrix exponential}
\index{discretization!matrix exponential}
\begin{remark}
  Watch the ``How (and why) to raise e to the power of a matrix" video from
  3Blue1Brown's \textit{Essence of linear algebra} series for a visual
  introduction to the matrix exponential.
  \begin{bookfigure}
    \qrcode{https://www.3blue1brown.com/lessons/matrix-exponents} \\
    ``How (and why) to raise e to the power of a matrix" (27 minutes) \\
    \footnotesize 3Blue1Brown \\
    \url{https://www.3blue1brown.com/lessons/matrix-exponents}
  \end{bookfigure}
\end{remark}
\begin{definition}[Matrix exponential]
  Let $\mat{X}$ be an $n \times n$ matrix. The exponential of $\mat{X}$ denoted
  by $e^{\mat{X}}$ is the $n \times n$ matrix given by the following power
  series.
  \begin{equation}
    e^{\mat{X}} = \sum_{k=0}^\infty \frac{1}{k!} \mat{X}^k \label{eq:mat_exp}
  \end{equation}

  where $\mat{X}^0$ is defined to be the identity matrix $\mat{I}$ with the same
  dimensions as $\mat{X}$.
\end{definition}

To understand why the matrix exponential is used in the \gls{discretization}
process, consider the scalar differential equation $\dot{x} = ax$. The solution
to this type of differential equation uses an exponential.
\begin{align*}
  \dot{x} &= ax \\
  \frac{dx}{dt} &= ax(t) \\
  dx &= ax(t) \,dt \\
  \frac{1}{x(t)} \,dx &= a \,dt \\
  \int_0^t \frac{1}{x(t)} \,dx &= \int_0^t a \,dt \\
  \ln(x(t)) \rvert_0^t &= at \rvert_0^t \\
  \ln(x(t)) - \ln(x(0)) &= at - a \cdot 0 \\
  \ln(x(t)) - \ln(x_0) &= at \\
  \ln\left(\frac{x(t)}{x_0}\right) &= at \\
  \frac{x(t)}{x_0} &= e^{at} \\
  x(t) &= e^{at} x_0
\end{align*}

This solution generalizes via the matrix exponential to the set of differential
equations $\dot{\mat{x}} = \mat{A}\mat{x} + \mat{B}\mat{u}$ we use to describe
\glspl{system}.\footnote{See section \ref{sec:deriv_linear_system_zoh} for a
complete derivation of the linear system zero-order hold.}
\begin{equation*}
  \mat{x}(t) = e^{\mat{A}t} \mat{x}_0 +
    \mat{A}^{-1}(e^{\mat{A}t} - \mat{I})\mat{B} \mat{u}
\end{equation*}

where $\mat{x}_0$ contains the initial conditions and $\mat{u}$ is the constant
input from time $0$ to $t$. If the initial \gls{state} is the current system
\gls{state}, then we can describe the \gls{system}'s \gls{state} over time as
\begin{align*}
  \mat{x}_{k+1} &= e^{\mat{A}T} \mat{x}_k +
    \mat{A}^{-1}(e^{\mat{A}T} - \mat{I})\mat{B} \mat{u}_k
  \intertext{or more compactly,}
  \mat{x}_{k+1} &= \mat{A}_d\mat{x}_k + \mat{B}_d\mat{u}_k
\end{align*}

where $T$ is the time between samples $\mat{x}_k$ and $\mat{x}_{k+1}$. Theorem
\ref{thm:linear_system_zoh} has more efficient ways to compute $\mat{A}_d$ and
$\mat{B}_d$.

\subsection{Definition}

The model can be \glslink{discretization}{discretized} as follows
\begin{align*}
  \mat{x}_{k+1} &= \mat{A}_d \mat{x}_k + \mat{B}_d \mat{u}_k + \mat{w}_k \\
   \mat{y}_k &= \mat{C}_d \mat{x}_k + \mat{D}_d \mat{u}_k + \mat{v}_k
\end{align*}

with covariances
\begin{align*}
  \mat{w}_k &\sim N(0, \mat{Q}_d) \\
  \mat{v}_k &\sim N(0, \mat{R}_d)
\end{align*}
\begin{theorem}[Linear system zero-order hold]
  \label{thm:linear_system_zoh}
  \begin{align}
    \mat{A}_d &= e^{\mat{A}_c T} \\
    \mat{B}_d &= \int_0^T e^{\mat{A}_c \tau} d\tau \mat{B}_c =
      \mat{A}_c^{-1} (\mat{A}_d - \mat{I}) \mat{B}_c \\
    \mat{C}_d &= \mat{C}_c \\
    \mat{D}_d &= \mat{D}_c \\
    \mat{Q}_d &= \int_{\tau = 0}^{T} e^{\mat{A}_c\tau} \mat{Q}_c
      e^{\mat{A}_c\T\tau} d\tau \\
    \mat{R}_d &= \frac{1}{T}\mat{R}_c
  \end{align}

  where subscripts $c$ and $d$ denote matrices for the continuous or discrete
  \glspl{system} respectively, $T$ is the sample period of the discrete
  \gls{system}, and $e^{\mat{A}_c T}$ is the matrix exponential of
  $\mat{A}_c T$.

  $\mat{A}_d$ and $\mat{B}_d$ can be computed in one step as
  \begin{equation*}
    e^{
    \begin{bmatrix}
      \mat{A}_c & \mat{B}_c \\
      \mat{0} & \mat{0}
    \end{bmatrix}T} =
    \begin{bmatrix}
      \mat{A}_d & \mat{B}_d \\
      \mat{0} & \mat{I}
    \end{bmatrix}
  \end{equation*}

  and $\mat{Q}_d$ can be computed as
  \begin{equation*}
    \Phi = e^{
    \begin{bmatrix}
      -\mat{A}_c & \mat{Q}_c \\
      \mat{0} & \mat{A}_c\T
    \end{bmatrix}T} =
    \begin{bmatrix}
      -\mat{A}_d & \mat{A}_d^{-1} \mat{Q}_d \\
      \mat{0} & \mat{A}_d\T
    \end{bmatrix}
  \end{equation*}

  where $\mat{Q}_d = \Phi_{2,2}\T \Phi_{1,2}$ \cite{bib:integral_matrix_exp}.
\end{theorem}

See appendix \ref{sec:deriv_linear_system_zoh} for derivations.

To see why $\mat{R}_c$ is being divided by $T$, consider the discrete white
noise sequence $\mat{v}_k$ and the (non-physically realizable) continuous white
noise process $\mat{v}$. Whereas $\mat{R}_{d,k} = E[\mat{v}_k \mat{v}_k\T]$ is a
covariance matrix, $\mat{R}_c(t)$ defined by
$E[\mat{v}(t) \mat{v}\T(\tau)] = \mat{R}_c(t)\delta(t - \tau)$ is a spectral
density matrix (the Dirac function $\delta(t - \tau)$ has units of
$1/\text{sec}$). The covariance matrix $\mat{R}_c(t)\delta(t - \tau)$ has
infinite-valued elements. The discrete white noise sequence can be made to
approximate the continuous white noise process by shrinking the pulse lengths
($T$) and increasing their amplitude, such that
$\mat{R}_d \rightarrow \frac{1}{T}\mat{R}_c$.

That is, in the limit as $T \rightarrow 0$, the discrete noise sequence tends to
one of infinite-valued pulses of zero duration such that the area under the
``impulse" autocorrelation function is $\mat{R}_d T$. This is equal to the area
$\mat{R}_c$ under the continuous white noise impulse autocorrelation function.
